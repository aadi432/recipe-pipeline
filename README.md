# ğŸ½ï¸ Recipe Analytics Pipeline (Firebase â†’ Python â†’ Analytics)

A complete **Data Engineering pipeline** built for transforming **NoSQL Firestore recipe data** into **validated, analytical datasets** with visual insights.

This project demonstrates:

- Firestore data ingestion  
- JSON export  
- Data normalization to CSV  
- Data validation (custom Great-Expectations style)  
- Analytics & visualizations  
- Retry logic & logging  
- Orchestration via a single pipeline runner  
- Dual data model (Firestore nested + CSV relational)

---

# ğŸ“ 1. Folder Structure

recipe-pipeline/
â”‚â”€â”€ analysis/ # Generated charts + insights
â”‚â”€â”€ exports/ # Raw JSON exports from Firestore
â”‚â”€â”€ outputs/
â”‚ â”œâ”€â”€ clean/ # Normalized cleaned CSVs
â”‚ â””â”€â”€ validated/ # Validation reports
â”‚â”€â”€ scripts/ # ETL, validation, analytics, orchestration scripts
â”‚â”€â”€ seed_data.json # Primary Pav Bhaji recipe
â”‚â”€â”€ serviceAccount.json # Firebase authentication key (ignored via .gitignore)
â”‚â”€â”€ .env # Secret environment variables
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md

yaml
Copy code

---

# ğŸ§  2. Project Overview

This pipeline executes an end-to-end workflow:

1ï¸âƒ£ Insert seed + synthetic recipe data into **Firebase Firestore**  
2ï¸âƒ£ Export Firestore â†’ **JSON**  
3ï¸âƒ£ Normalize JSON â†’ **clean CSV datasets**  
4ï¸âƒ£ Validate CSVs using a **custom Great-Expectations style validator**  
5ï¸âƒ£ Run analytics and generate **11+ charts**  
6ï¸âƒ£ Fully orchestrated with **run_pipeline.py**

This simulates a real-world Data Engineering solution using a mix of NoSQL + relational modeling.

---

# ğŸ§© 3. Data Model (ER Diagram)

The project uses **two data models**:

---

## ğŸ”· 3.1 Firestore ERD (Nested NoSQL Model)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RECIPES â”‚
â”‚ id, title, desc, times, ... â”‚
â”‚ ingredients: [ {name, qty} ] â”‚
â”‚ steps: [ {order, text} ] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ 1-to-many
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INTERACTIONS â”‚
â”‚ recipe_id, user_id â”‚
â”‚ type, rating, timestampâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ many-to-1
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USERS â”‚
â”‚ id, name â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

yaml
Copy code

### Relationships
- Recipe â†’ Ingredients = **1:N**  
- Recipe â†’ Steps = **1:N**  
- Recipe â†’ Interactions = **1:N**  
- User â†’ Interactions = **1:N**

---

## ğŸ”· 3.2 CSV / Analytics ERD (Flattened Relational)

RECIPES_CLEAN â”€â”€â”€â”¬â”€â”€â”€< INGREDIENTS_CLEAN
â”œâ”€â”€â”€< STEPS_CLEAN
â””â”€â”€â”€< INTERACTIONS_CLEAN >â”€â”€ USERS_CLEAN

yaml
Copy code

Used for analytics & reporting.

---

# ğŸ› 4. Primary Dataset (Your Recipe)

### ğŸŸ¢ Primary real recipe: **Pav Bhaji**

This satisfies the assignment requirement to include one **real recipe created by the candidate**.

Included fields:
- Ingredients (with quantities)
- Step-by-step instructions
- Time & difficulty
- Cuisine, region, tags

Stored in `seed_data.json`.

### ğŸŸ¡ Synthetic Data (Auto-generated)
- **19 vegetarian recipes**
- **10 sample Indian users**
- **120+ interactions** (view/like/cook_attempt)

---

# âš™ï¸ 5. ETL / ELT Pipeline Steps

## ğŸ”¹ Step 1 â€” Firestore Setup
Script: `1_setup_firestore.py`

- Loads Pav Bhaji (primary recipe)
- Generates 19 synthetic recipes
- Creates users
- Creates interactions
- Includes **retry logic + logging**

---

## ğŸ”¹ Step 2 â€” Export Firestore â†’ JSON
Script: `2_export_firestore.py`

Exports:
exports/recipes.json
exports/users.json
exports/interactions.json

yaml
Copy code

---

## ğŸ”¹ Step 3 â€” Transform JSON â†’ Clean CSVs
Script: `3_transform_to_csv.py`

Outputs:
outputs/clean/recipes_clean.csv
outputs/clean/ingredients_clean.csv
outputs/clean/steps_clean.csv
outputs/clean/users_clean.csv
outputs/clean/interactions_clean.csv

yaml
Copy code

Includes:
- Flattening nested arrays  
- Normalization  
- Retry-safe reading  

---

## ğŸ”¹ Step 4 â€” Data Validation (Custom GE-Style)
Script: `4_validate_csv.py`  
AND  
Script: `4a_custom_expectations_check.py` (Great-Expectations style)

Validates:
- Required columns  
- Unique IDs  
- No NULLs in key fields  
- Integer columns valid  
- Foreign keys valid  
- Step order valid  

Output:
outputs/validated/validation_report.txt
outputs/validated/custom_ge_report.txt

yaml
Copy code

---

## ğŸ”¹ Step 5 â€” Analytics & Visualizations
Script: `5_analytics.py`

Generates 10+ charts:
- Top ingredients  
- Difficulty distribution  
- Prep vs likes correlation  
- Top viewed recipes  
- Step count distribution  
- Top engaged recipes  
- Most active users  
- Complexity score distribution  
- Engagement score analysis  
- Etc.

Saved to:
analysis/*.png
analysis/insights_summary.txt

yaml
Copy code

---

# ğŸ” 6. Pipeline Orchestration

Script: `run_pipeline.py`

Runs all steps in the correct order:

python scripts/run_pipeline.py

yaml
Copy code

Includes:
- Error boundaries  
- Logging  
- Full automation  

---

# âœ”ï¸ 7. Data Quality Rules Summary

### ğŸŸ¦ Recipes
- id, title required  
- Difficulty âˆˆ {easy, medium, hard}  
- prep/cook times â‰¥ 0  
- No missing timestamps  

### ğŸŸ© Ingredients
- recipe_id required  
- ingredient_name required  

### ğŸŸ¨ Steps
- recipe_id required  
- step order â‰¥ 1  
- sequential per recipe  

### ğŸŸ§ Users
- id unique  
- name not null  

### ğŸŸ¥ Interactions
- recipe_id + user_id must reference valid tables  
- type âˆˆ {view, like, cook_attempt}  
- rating âˆˆ {1â€“5 or null}

---

# ğŸ“Š 8. Sample Insights Generated

- Most frequent ingredients  
- Top 10 most viewed recipes  
- Difficulty distribution  
- Prep time vs likes correlation  
- Step count analysis  
- Engagement score ranking  
- Ingredient frequency in high-engagement recipes  
- Most active 20 users  
- Complexity score analysis  

All charts saved under `analysis/`.

---

# â–¶ï¸ 9. How to Run the Pipeline

### Install dependencies:
```bash
pip install -r requirements.txt
Add Firebase Secret Key
Place your:

pgsql
Copy code
serviceAccount.json
in the project root.

Add .env file:
ini
Copy code
SERVICE_ACCOUNT_PATH=serviceAccount.json
PAV_SEED_PATH=seed_data.json
Run the full pipeline:
bash
Copy code
python scripts/run_pipeline.py
âš ï¸ 10. Limitations
Synthetic recipe descriptions are random

Ratings partially random

Requires correct Firebase config

Focused on vegetarian recipes only

ğŸ¯ 11. What This Submission Demonstrates
End-to-end Data Engineering pipeline

ETL + data modeling

Semi-structured â†’ structured transformation

Data quality checks

Analytical model creation

Visualization engineering

Retry logic + error handling

Orchestration (one-click pipeline)

ğŸ“˜ Conclusion
This project shows a complete academic-style Data Engineering solution, transforming raw Firestore (NoSQL) data into clean, validated, analytics-ready tables. It includes modeling, validation, visualizations, and orchestration, making it suitable for real-world pipelines and technical assignments.

ğŸ™Œ Author
Aditya Shukla
